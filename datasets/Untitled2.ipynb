{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8614966-4a57-4cb6-9517-67be4ff30b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfc265-1471-4b26-b587-16020c4e1ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Tokenizing text in cxr_reports and mimic_notes...\n",
      "Generating MinHash signatures for cxr_reports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CXR MinHash Generation: 100%|██████████| 227835/227835 [02:43<00:00, 1396.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed MinHash signature generation for cxr_reports.\n",
      "Building the LSH index for cxr_reports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LSH Index: 100%|██████████| 227835/227835 [00:02<00:00, 111734.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSH index built for cxr_reports.\n",
      "Generating MinHash signatures for mimic_notes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MIMIC MinHash Generation:   0%|          | 0/2321355 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "# Parameters\n",
    "NUM_PERMUTATIONS = 64  # Reduced for speed\n",
    "JACCARD_THRESHOLD = 0.95  # High similarity threshold\n",
    "BATCH_SIZE = 100000  # Adjust batch size based on available memory and CPU\n",
    "\n",
    "# MinHash signature creation function\n",
    "def create_minhash_signature(tokens):\n",
    "    m = MinHash(num_perm=NUM_PERMUTATIONS)\n",
    "    for token in tokens:\n",
    "        m.update(token.encode('utf8'))\n",
    "    return m\n",
    "\n",
    "# Preprocess and tokenize text\n",
    "def preprocess_and_tokenize(text):\n",
    "    if pd.isnull(text):\n",
    "        return set()\n",
    "    tokens = text.split()\n",
    "    return set(tokens)\n",
    "\n",
    "# Helper function to process a batch of data\n",
    "def process_batch_min_hash(data):\n",
    "    return data.apply(create_minhash_signature)\n",
    "\n",
    "# Load datasets and apply tokenization\n",
    "print(\"Loading datasets...\")\n",
    "cxr_reports = pd.read_csv(\"/scratch/baj321/cxr_reports.csv\")  # Adjust path to file\n",
    "mimic_notes = pd.read_csv(\"/scratch/baj321/MIMIC-Note/physionet.org/files/mimic-iv-note/2.2/note/radiology.csv\")  # Adjust path to file\n",
    "\n",
    "print(\"Tokenizing text in cxr_reports and mimic_notes...\")\n",
    "cxr_reports['tokens'] = cxr_reports['cxr_report_text'].apply(preprocess_and_tokenize)\n",
    "mimic_notes['tokens'] = mimic_notes['text'].apply(preprocess_and_tokenize)\n",
    "\n",
    "# Generate MinHash signatures for cxr_reports with progress tracking\n",
    "print(\"Generating MinHash signatures for cxr_reports...\")\n",
    "cpu_cores = cpu_count()\n",
    "with Pool(cpu_cores) as pool:\n",
    "    cxr_reports['minhash'] = list(tqdm(pool.imap(create_minhash_signature, cxr_reports['tokens'], BATCH_SIZE),\n",
    "                                       total=len(cxr_reports),\n",
    "                                       desc=\"CXR MinHash Generation\"))\n",
    "print(\"Completed MinHash signature generation for cxr_reports.\")\n",
    "\n",
    "# Build the LSH index for cxr_reports\n",
    "print(\"Building the LSH index for cxr_reports...\")\n",
    "lsh = MinHashLSH(threshold=JACCARD_THRESHOLD, num_perm=NUM_PERMUTATIONS)\n",
    "for idx, minhash in tqdm(enumerate(cxr_reports['minhash']), total=len(cxr_reports), desc=\"Building LSH Index\"):\n",
    "    lsh.insert(f\"cxr_{idx}\", minhash)\n",
    "print(\"LSH index built for cxr_reports.\")\n",
    "\n",
    "# Generate MinHash signatures for mimic_notes in parallel with progress tracking\n",
    "print(\"Generating MinHash signatures for mimic_notes...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['minhash'] = list(tqdm(pool.imap(create_minhash_signature, mimic_notes['tokens'], BATCH_SIZE),\n",
    "                                       total=len(mimic_notes),\n",
    "                                       desc=\"MIMIC MinHash Generation\"))\n",
    "print(\"Completed MinHash signature generation for mimic_notes.\")\n",
    "\n",
    "# Function to check similarity for a single MinHash signature\n",
    "def is_similar(mimic_report_minhash):\n",
    "    return len(lsh.query(mimic_report_minhash)) > 0\n",
    "\n",
    "# Check for similarity in batches with progress tracking\n",
    "print(\"Checking similarity of mimic_notes against cxr_reports in batches...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['is_similar'] = list(tqdm(pool.imap(is_similar, mimic_notes['minhash'], BATCH_SIZE),\n",
    "                                          total=len(mimic_notes),\n",
    "                                          desc=\"Similarity Check\"))\n",
    "print(\"Similarity check completed.\")\n",
    "\n",
    "# Filter out similar reports to get unique reports in mimic_notes\n",
    "print(\"Filtering unique mimic_notes that are not in cxr_reports...\")\n",
    "unique_mimic_notes = mimic_notes[~mimic_notes['is_similar']]\n",
    "\n",
    "# Display or save results\n",
    "print(\"Displaying unique mimic_notes...\")\n",
    "print(unique_mimic_notes.head())  # Display the first few rows\n",
    "unique_mimic_notes.to_csv(\"/scratch/baj321/unique_mimic_notes.csv\", index=False)  # Save to a CSV file for further analysis\n",
    "print(\"Unique mimic_notes saved to '/scratch/baj321/unique_mimic_radiology_notes.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df439ec-76ff-4a85-a3eb-51ba17e6d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate MinHash signatures for cxr_reports with progress tracking\n",
    "print(\"Generating MinHash signatures for cxr_reports...\")\n",
    "cpu_cores = cpu_count()\n",
    "with Pool(cpu_cores) as pool:\n",
    "    cxr_reports['minhash'] = list(tqdm(pool.imap_unordered(create_minhash_signature, cxr_reports['tokens']), \n",
    "                                       total=len(cxr_reports), \n",
    "                                       desc=\"CXR MinHash Generation\"))\n",
    "print(\"Completed MinHash signature generation for cxr_reports.\")\n",
    "\n",
    "# Generate MinHash signatures for mimic_notes in parallel with progress tracking\n",
    "print(\"Generating MinHash signatures for mimic_notes...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['minhash'] = list(tqdm(pool.imap_unordered(create_minhash_signature, mimic_notes['tokens']), \n",
    "                                       total=len(mimic_notes), \n",
    "                                       desc=\"MIMIC MinHash Generation\"))\n",
    "print(\"Completed MinHash signature generation for mimic_notes.\")\n",
    "\n",
    "# Check for similarity in batches with progress tracking\n",
    "print(\"Checking similarity of mimic_notes against cxr_reports in batches...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['is_similar'] = list(tqdm(pool.imap_unordered(is_similar, mimic_notes['minhash']), \n",
    "                                          total=len(mimic_notes), \n",
    "                                          desc=\"Similarity Check\"))\n",
    "print(\"Similarity check completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medfuse_py37",
   "language": "python",
   "name": "medfuse_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
