{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5261c821-e2dc-45a8-8aef-4cc6886c234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataframe (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032-RR-14</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>14</td>\n",
       "      <td>2180-05-06 21:19:00</td>\n",
       "      <td>2180-05-06 23:32:00</td>\n",
       "      <td>EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032-RR-15</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>15</td>\n",
       "      <td>2180-05-06 23:00:00</td>\n",
       "      <td>2180-05-06 23:26:00</td>\n",
       "      <td>EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032-RR-16</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>16</td>\n",
       "      <td>2180-05-07 09:55:00</td>\n",
       "      <td>2180-05-07 11:15:00</td>\n",
       "      <td>INDICATION:  ___ HCV cirrhosis c/b ascites, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032-RR-18</td>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "      <td>18</td>\n",
       "      <td>2180-06-03 12:46:00</td>\n",
       "      <td>2180-06-03 14:01:00</td>\n",
       "      <td>EXAMINATION:  Ultrasound-guided paracentesis.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032-RR-20</td>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "      <td>20</td>\n",
       "      <td>2180-07-08 13:18:00</td>\n",
       "      <td>2180-07-08 14:15:00</td>\n",
       "      <td>EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id  subject_id     hadm_id note_type  note_seq  \\\n",
       "0  10000032-RR-14    10000032  22595853.0        RR        14   \n",
       "1  10000032-RR-15    10000032  22595853.0        RR        15   \n",
       "2  10000032-RR-16    10000032  22595853.0        RR        16   \n",
       "3  10000032-RR-18    10000032         NaN        RR        18   \n",
       "4  10000032-RR-20    10000032         NaN        RR        20   \n",
       "\n",
       "             charttime            storetime  \\\n",
       "0  2180-05-06 21:19:00  2180-05-06 23:32:00   \n",
       "1  2180-05-06 23:00:00  2180-05-06 23:26:00   \n",
       "2  2180-05-07 09:55:00  2180-05-07 11:15:00   \n",
       "3  2180-06-03 12:46:00  2180-06-03 14:01:00   \n",
       "4  2180-07-08 13:18:00  2180-07-08 14:15:00   \n",
       "\n",
       "                                                text  \n",
       "0  EXAMINATION:  CHEST (PA AND LAT)\\n\\nINDICATION...  \n",
       "1  EXAMINATION:  LIVER OR GALLBLADDER US (SINGLE ...  \n",
       "2  INDICATION:  ___ HCV cirrhosis c/b ascites, hi...  \n",
       "3  EXAMINATION:  Ultrasound-guided paracentesis.\\...  \n",
       "4  EXAMINATION:  Paracentesis\\n\\nINDICATION:  ___...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a sample of the CSV file first to get an overview\n",
    "file_path = '/scratch/baj321/MIMIC-Note/physionet.org/files/mimic-iv-note/2.2/note/radiology.csv'\n",
    "# Display the first few rows of the dataframe to get an overview\n",
    "mimic_note_df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First few rows of the dataframe (sample):\")\n",
    "display(mimic_note_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbbcde2-7c14-4b12-9b2c-37116576d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataframe (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>cxr_report_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14591045</td>\n",
       "      <td>57685699</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14591045</td>\n",
       "      <td>52357049</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14591045</td>\n",
       "      <td>51433247</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14591045</td>\n",
       "      <td>57096030</td>\n",
       "      <td>WET READ: ___ ___ ___ 8:11 AM\\n  \\n  Tiny lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14591045</td>\n",
       "      <td>56519652</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id                                    cxr_report_text\n",
       "0    14591045  57685699                                   FINAL REPORT\\...\n",
       "1    14591045  52357049                                   FINAL REPORT\\...\n",
       "2    14591045  51433247                                   FINAL REPORT\\...\n",
       "3    14591045  57096030   WET READ: ___ ___ ___ 8:11 AM\\n  \\n  Tiny lef...\n",
       "4    14591045  56519652                                   FINAL REPORT\\..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a sample of the CSV file first to get an overview\n",
    "file_path = '/scratch/baj321/cxr_reports.csv'\n",
    "# Display the first few rows of the dataframe to get an overview\n",
    "mimic_cxr_reports = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First few rows of the dataframe (sample):\")\n",
    "display(mimic_cxr_reports.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644ae62e-4904-4667-82ac-dd3bb0a442fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2321355"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mimic_note_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe55357-8eea-4872-a5a3-97bd4d888965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from Levenshtein import distance\n",
    "\n",
    "# Convert mimic_note_df to a Dask DataFrame\n",
    "mimic_note_df_dd = dd.from_pandas(mimic_note_df, npartitions=20)\n",
    "cxr_report_texts_set = set(mimic_cxr_reports['cxr_report_text'].dropna().unique())\n",
    "similarity_threshold = 0.9\n",
    "\n",
    "print(\"Loaded\")\n",
    "\n",
    "# Define a delayed function to calculate Levenshtein similarity\n",
    "@delayed\n",
    "def levenshtein_similarity(text1, text2):\n",
    "    lev_distance = distance(text1, text2)\n",
    "    max_len = max(len(text1), len(text2))\n",
    "    similarity = 1 - (lev_distance / max_len) if max_len > 0 else 1\n",
    "    return similarity\n",
    "\n",
    "# Define a delayed function to check if a note is unique based on the similarity threshold\n",
    "@delayed\n",
    "def is_unique_note_delayed(note_text, cxr_report_texts_set, threshold):\n",
    "    for report_text in cxr_report_texts_set:\n",
    "        if levenshtein_similarity(note_text, report_text).compute() >= threshold:\n",
    "            return False  # Not unique if any report is similar enough\n",
    "    return True  # Unique if no similar report found\n",
    "\n",
    "# Apply the function with Dask's map_partitions\n",
    "def check_uniqueness_partition(partition, cxr_report_texts_set, threshold):\n",
    "    return partition[partition['text'].apply(lambda note: is_unique_note_delayed(note, cxr_report_texts_set, threshold).compute())]\n",
    "\n",
    "# Apply check_uniqueness_partition across partitions in Dask\n",
    "mimic_notes_unique_dd = mimic_note_df_dd.map_partitions(check_uniqueness_partition, cxr_report_texts_set=cxr_report_texts_set, threshold=similarity_threshold)\n",
    "\n",
    "# Trigger computation and get the length\n",
    "mimic_notes_unique = mimic_notes_unique_dd.compute()\n",
    "len(mimic_notes_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f6972-e9df-460a-9db3-c79b77a467be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/scratch/baj321/other_reports.csv'  # Replace with your desired file path\n",
    "mimic_notes_unique.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"DataFrame has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2483674-9bb3-4e72-b6c3-6cc497a3febf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading Levenshtein-0.21.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.11.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 52.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
      "Successfully installed Levenshtein-0.21.1 rapidfuzz-2.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6e311-f69f-498b-a754-7aa6bc0c6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "\n",
    "# Assume mimic_cxr_reports and mimic_note_df are your DataFrames\n",
    "# cxr_report_texts_set = set(mimic_cxr_reports['cxr_report_text'].dropna().unique())\n",
    "# mimic_note_df['text'] contains the notes to compare\n",
    "\n",
    "# Define a function to calculate Levenshtein similarity\n",
    "def levenshtein_similarity(text1, text2):\n",
    "    lev_distance = distance(text1, text2)\n",
    "    max_len = max(len(text1), len(text2))\n",
    "    similarity = 1 - (lev_distance / max_len) if max_len > 0 else 1\n",
    "    return similarity\n",
    "\n",
    "# Set your similarity threshold (e.g., 0.8 for 80% similarity)\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "# Define a function to check if a note is unique based on the similarity threshold\n",
    "def is_unique_note(note_text, cxr_report_texts_set, threshold):\n",
    "    for report_text in cxr_report_texts_set:\n",
    "        if levenshtein_similarity(note_text, report_text) >= threshold:\n",
    "            return False  # Not unique if any report is similar enough\n",
    "    return True  # Unique if no similar report found\n",
    "\n",
    "# Apply the function to filter mimic_note_df\n",
    "mimic_notes_unique = mimic_note_df[mimic_note_df['text'].apply(lambda note: is_unique_note(note, cxr_report_texts_set, similarity_threshold))]\n",
    "\n",
    "# Display the result\n",
    "len(mimic_notes_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025ca86-f146-4d56-b133-2ca6145f57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Tokenizing text in cxr_reports and mimic_notes...\n",
      "Generating MinHash signatures for cxr_reports...\n",
      "Completed MinHash signature generation for cxr_reports.\n",
      "Building the LSH index for cxr_reports...\n",
      "LSH index built for cxr_reports.\n",
      "Generating MinHash signatures for mimic_notes...\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "NUM_PERMUTATIONS = 64  # Reduced for speed\n",
    "JACCARD_THRESHOLD = 0.95  # High similarity threshold\n",
    "BATCH_SIZE = 100000  # Adjust batch size based on available memory and CPU\n",
    "\n",
    "# MinHash signature creation function\n",
    "def create_minhash_signature(tokens):\n",
    "    m = MinHash(num_perm=NUM_PERMUTATIONS)\n",
    "    for token in tokens:\n",
    "        m.update(token.encode('utf8'))\n",
    "    return m\n",
    "\n",
    "# Preprocess and tokenize text\n",
    "def preprocess_and_tokenize(text):\n",
    "    if pd.isnull(text):\n",
    "        return set()\n",
    "    # Normalize text: lowercase, remove non-alphanumeric characters, split into words\n",
    "    #text = text.lower()\n",
    "    #text = ''.join(e for e in text if e.isalnum() or e.isspace())\n",
    "    tokens = text.split()\n",
    "    return set(tokens)\n",
    "\n",
    "# Helper function to process a batch of data\n",
    "def process_batch_min_hash(data):\n",
    "    return data.apply(create_minhash_signature)\n",
    "\n",
    "# Load datasets and apply tokenization\n",
    "print(\"Loading datasets...\")\n",
    "cxr_reports = pd.read_csv(\"/scratch/baj321/cxr_reports.csv\")  # Adjust path to file\n",
    "mimic_notes = pd.read_csv(\"/scratch/baj321/MIMIC-Note/physionet.org/files/mimic-iv-note/2.2/note/radiology.csv\")  # Adjust path to file\n",
    "\n",
    "print(\"Tokenizing text in cxr_reports and mimic_notes...\")\n",
    "cxr_reports['tokens'] = cxr_reports['cxr_report_text'].apply(preprocess_and_tokenize)\n",
    "mimic_notes['tokens'] = mimic_notes['text'].apply(preprocess_and_tokenize)\n",
    "\n",
    "# Generate MinHash signatures for cxr_reports\n",
    "print(\"Generating MinHash signatures for cxr_reports...\")\n",
    "cpu_cores = cpu_count()\n",
    "with Pool(cpu_cores) as pool:\n",
    "    cxr_reports['minhash'] = pool.map(create_minhash_signature, cxr_reports['tokens'], BATCH_SIZE)\n",
    "print(\"Completed MinHash signature generation for cxr_reports.\")\n",
    "\n",
    "# Build the LSH index for cxr_reports\n",
    "print(\"Building the LSH index for cxr_reports...\")\n",
    "lsh = MinHashLSH(threshold=JACCARD_THRESHOLD, num_perm=NUM_PERMUTATIONS)\n",
    "for idx, minhash in enumerate(cxr_reports['minhash']):\n",
    "    lsh.insert(f\"cxr_{idx}\", minhash)\n",
    "print(\"LSH index built for cxr_reports.\")\n",
    "\n",
    "# Generate MinHash signatures for mimic_notes in parallel\n",
    "print(\"Generating MinHash signatures for mimic_notes...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['minhash'] = pool.map(create_minhash_signature, mimic_notes['tokens'], BATCH_SIZE)\n",
    "print(\"Completed MinHash signature generation for mimic_notes.\")\n",
    "\n",
    "# Function to check similarity for a single MinHash signature\n",
    "def is_similar(mimic_report_minhash):\n",
    "    return len(lsh.query(mimic_report_minhash)) > 0\n",
    "\n",
    "# Check for similarity in batches\n",
    "print(\"Checking similarity of mimic_notes against cxr_reports in batches...\")\n",
    "with Pool(cpu_cores) as pool:\n",
    "    mimic_notes['is_similar'] = pool.map(is_similar, mimic_notes['minhash'], BATCH_SIZE)\n",
    "print(\"Similarity check completed.\")\n",
    "\n",
    "# Filter out similar reports to get unique reports in mimic_notes\n",
    "print(\"Filtering unique mimic_notes that are not in cxr_reports...\")\n",
    "unique_mimic_notes = mimic_notes[~mimic_notes['is_similar']]\n",
    "\n",
    "# Display or save results\n",
    "print(\"Displaying unique mimic_notes...\")\n",
    "print(unique_mimic_notes.head())  # Display the first few rows\n",
    "unique_mimic_notes.to_csv(\"/scratch/baj321/unique_mimic_notes.csv\", index=False)  # Save to a CSV file for further analysis\n",
    "print(\"Unique mimic_notes saved to '/scratch/baj321/unique_mimic_radiology_notes.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453606d4-de5f-4d32-b30f-338b07fba39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasketch\n",
      "  Downloading datasketch-1.6.5-py3-none-any.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 5.0 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /home/baj321/.conda/envs/medfuse/lib/python3.6/site-packages (from datasketch) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/baj321/.conda/envs/medfuse/lib/python3.6/site-packages (from datasketch) (1.5.2)\n",
      "Installing collected packages: datasketch\n",
      "Successfully installed datasketch-1.6.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8877a-e7d6-413f-85f3-71f20e071719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medfuse_py37",
   "language": "python",
   "name": "medfuse_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
